{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import math\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.base import (BaseEstimator, TransformerMixin)\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data used for this analysis will be a 2009 survey conducted for the H1N1 outbreak. This survey was performed by the CDC in order to monitor and evaluate the flu vaccination efforts of adults and children in randomly selected US households. The questions asked of the participants dealt with their H1N1 vaccination status, flu-related behaviors, opinions about flu vaccine safety and effectivenss, recent respiratory illness, and pneumococcal vaccination status <a href=\"#About the National Immunization Survery\">[1]</a>.\n",
    "\n",
    "The following data from the survey can be found and downloaded <a href=\"https://www.drivendata.org/competitions/66/flu-shot-learning/data/\">here</a><a href=\"#Source Data Download\">[2]</a> with feature descriptions found <a href=\"https://github.com/cschneck7/Iterative_Classification_Blog/blob/main/data/H1N1_and_Seasonal_Flu_Vaccines_Feature_Information.txt\">here</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import survey data into dataframes\n",
    "# The source dataset already had this split feature and target files\n",
    "X = pd.read_csv('data/source_data/training_set_features.csv')\n",
    "y = pd.read_csv('data/source_data/training_set_labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are originally two different target variable, for this example we will only concentrate on `h1n1_vaccine`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets target variable\n",
    "y = y.h1n1_vaccine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick look at feature dataframe shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26707, 36)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Returns shape of feature dataframe\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick look at missing values in feature dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "respondent_id                      0\n",
       "h1n1_concern                      92\n",
       "h1n1_knowledge                   116\n",
       "behavioral_antiviral_meds         71\n",
       "behavioral_avoidance             208\n",
       "behavioral_face_mask              19\n",
       "behavioral_wash_hands             42\n",
       "behavioral_large_gatherings       87\n",
       "behavioral_outside_home           82\n",
       "behavioral_touch_face            128\n",
       "doctor_recc_h1n1                2160\n",
       "doctor_recc_seasonal            2160\n",
       "chronic_med_condition            971\n",
       "child_under_6_months             820\n",
       "health_worker                    804\n",
       "health_insurance               12274\n",
       "opinion_h1n1_vacc_effective      391\n",
       "opinion_h1n1_risk                388\n",
       "opinion_h1n1_sick_from_vacc      395\n",
       "opinion_seas_vacc_effective      462\n",
       "opinion_seas_risk                514\n",
       "opinion_seas_sick_from_vacc      537\n",
       "age_group                          0\n",
       "education                       1407\n",
       "race                               0\n",
       "sex                                0\n",
       "income_poverty                  4423\n",
       "marital_status                  1408\n",
       "rent_or_own                     2042\n",
       "employment_status               1463\n",
       "hhs_geo_region                     0\n",
       "census_msa                         0\n",
       "household_adults                 249\n",
       "household_children               249\n",
       "employment_industry            13330\n",
       "employment_occupation          13470\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checks amount of Nan values in feature dataframe\n",
    "missing_values = X.isna().sum()\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most Frequent Entry Imputation\n",
    "\n",
    "Below we observe the normalized distribution of a feature missing only a few entries and one containing many missed entries. We will use these two features to observe how using most frequent entry imputation is good for features that are almost complete though creates a bias for features missing most entries. This bias is very noticable if the original distribution is almost evenly spread, while less severe and possibly usable at distributions that are very far apart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values: 19\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0    0.931018\n",
       "1.0    0.068982\n",
       "Name: behavioral_face_mask, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values: 12274\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0    0.87972\n",
       "0.0    0.12028\n",
       "Name: health_insurance, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Takes both a feature with little and many missing entries\n",
    "X_missing = X[['behavioral_face_mask', 'health_insurance']]\n",
    "\n",
    "# Displays number of missing values as well as normalized\n",
    "# value distribution of existing values in percentages\n",
    "print(f'Number of missing values: {X_missing.behavioral_face_mask.isna().sum()}')\n",
    "print(X_missing.behavioral_face_mask.value_counts(normalize=True))\n",
    "print(f'Number of missing values: {X_missing.health_insurance.isna().sum()}')\n",
    "print(X_missing.health_insurance.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imputing the most frequent entry using SimpleImputer then analyzing the new distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values: 0\n",
      "0.0    0.931067\n",
      "1.0    0.068933\n",
      "Name: behavioral_face_mask, dtype: float64\n",
      "Number of missing values: 0\n",
      "1.0    0.934998\n",
      "0.0    0.065002\n",
      "Name: health_insurance, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Creating a simple imputer object with strategy of most_frequent\n",
    "si = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "# creates dataframe of transformed features\n",
    "X_most_frequent = pd.DataFrame(data=si.fit_transform(X_missing),\n",
    "                               index=X_missing.index,\n",
    "                               columns=X_missing.columns)\n",
    "\n",
    "\n",
    "# Displays new value distributions after imputation\n",
    "print(f'Number of missing values: {X_most_frequent.behavioral_face_mask.isna().sum()}')\n",
    "print(X_most_frequent.behavioral_face_mask.value_counts(normalize=True))\n",
    "print(f'Number of missing values: {X_most_frequent.health_insurance.isna().sum()}')\n",
    "print(X_most_frequent.health_insurance.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen above this imputation method barely changed the distribution of values for `behavioural_face_mask` which was only missing 19 entries. On the other hand the feature `health_insurance` which was missing nearly half its values had its distibution spread increase by nearly 11%. Even though there was already a mismatched distribution the most frequent entry imputation method created a larger bias in value distribution.\n",
    "\n",
    "### Random Imputation\n",
    "\n",
    "Next we will take a quick look at random imputation. This method randomly imputes values based of the existing values distribution. This may already be more attractive than the previous method because it ensures the distribution will stay constant. We'll use the same values as before to provide an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "behavioral_face_mask\n",
      "\n",
      "Original Distribution:\n",
      "Number of missing values: 19\n",
      "0.0    0.931018\n",
      "1.0    0.068982\n",
      "Name: behavioral_face_mask, dtype: float64\n",
      "\n",
      "Distribution after random imputation:\n",
      "Number of missing values: 0\n",
      "0.0    0.931029\n",
      "1.0    0.068971\n",
      "Name: behavioral_face_mask, dtype: float64\n",
      "\n",
      "-------------------------------------------------------------\n",
      "\n",
      "health_insurance\n",
      "\n",
      "Original Distribution:\n",
      "Number of missing values: 12274\n",
      "1.0    0.87972\n",
      "0.0    0.12028\n",
      "Name: health_insurance, dtype: float64\n",
      "\n",
      "Distribution after random imputation:\n",
      "Number of missing values: 0\n",
      "1.0    0.879957\n",
      "0.0    0.120043\n",
      "Name: health_insurance, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Creates copy of DataFrame\n",
    "X_rand_imp = X_missing.copy()\n",
    "\n",
    "# Iterates through features\n",
    "for col in X_missing.columns:\n",
    "#     Finds number of missing values in feature\n",
    "    number_missing = X_rand_imp[col].isnull().sum()\n",
    "#     Finds normalized distribution of existing entries\n",
    "    value_dist = X_rand_imp.loc[X_rand_imp[col].notnull(), col].value_counts(normalize=True)\n",
    "#     Sets random seed for random.choice\n",
    "    np.random.seed(0)\n",
    "#     Randomly Imputes observed values replacing all missing information\n",
    "    X_rand_imp.loc[X_rand_imp[col].isnull(), col] = np.random.choice(value_dist.index, \n",
    "                                                                     number_missing, \n",
    "                                                                     replace = True,\n",
    "                                                                     p = value_dist)\n",
    "    \n",
    "# Displays before and after imputation distributions\n",
    "print('behavioral_face_mask\\n')\n",
    "print(f'Original Distribution:\\nNumber of missing values: {X_missing.behavioral_face_mask.isna().sum()}')\n",
    "print(X_missing.behavioral_face_mask.value_counts(normalize=True))\n",
    "print(f'\\nDistribution after random imputation:\\nNumber of missing values: {X_rand_imp.behavioral_face_mask.isna().sum()}')\n",
    "print(X_rand_imp.behavioral_face_mask.value_counts(normalize=True))\n",
    "print('\\n-------------------------------------------------------------\\n')\n",
    "print('health_insurance\\n')\n",
    "print(f'Original Distribution:\\nNumber of missing values: {X_missing.health_insurance.isna().sum()}')\n",
    "print(X_missing.health_insurance.value_counts(normalize=True))\n",
    "print(f'\\nDistribution after random imputation:\\nNumber of missing values: {X_rand_imp.health_insurance.isna().sum()}')\n",
    "print(X_rand_imp.health_insurance.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen above this method maintains the original distribution of values after imputation. It should be noted that while this method maintains the distribution of the original feature, the accuracy of imputed entries drops in comparison to the most frequent entry imputation approach. If you assume the missing entries follow the same distribution as the original, by imputing the most frequent entry the accuracy will be equal to the distribution of that most frequent entry in the original data. For example if the distribution is 80:20 for existing values, the accuracy of most frequent entry imputation will be 80%. While the accuracy of using the above random imputation method is only 68%. This can be found by considering of the 80% of values randomly imputed as the most frequent value, only 80% of them will be correct and vice versa for the less frequent value. The math works out as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68.00000000000001"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100*((.8*.8) + (.2*.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[1] <a id='About the National Immunization Survery' href=\"https://webarchive.loc.gov/all/20140511031000/http://www.cdc.gov/nchs/nis/about_nis.htm#h1n1\">https://webarchive.loc.gov/all/20140511031000/http://www.cdc.gov/nchs/nis/about_nis.htm#h1n1</a>\n",
    "\n",
    "[2] <a href='https://www.drivendata.org/competitions/66/flu-shot-learning/data/'>https://www.drivendata.org/competitions/66/flu-shot-learning/data/</a>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
